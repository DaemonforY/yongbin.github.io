本章从ODS表的抽取方法、数据质量处理、表的设计方法三个方面详细阐述了ODS具体是如何实现的。最后，通过生产实践的场景分析总结了不同业务场景下选用最佳的设计方法：综合考虑计算及存储成本、用户需求的实现程度以及保障良好的数据质量下，选用哪一种抽取方法、数据库表需要如何设计、生命周期如何选择等。

# ODS表的抽取

  前文已经说明ODS的数据来源于业务系统，且ODS落地的系统通常和业务系统是不同的，那么我们就需要将业务系统的数据抽取到ODS表中。通常可以分为三类抽取：文件抽取、数据库表的抽取和原始日志的抽取。

## 1）文件抽取

  由于ODS落地的物理库通常和业务系统是不同的，并且ODS对接往往的不是一个单一的业务系统，可能涉及到各种类型的数据库（DB2、Oracle、Mysql等等），一种比较简单实用的做法是和各个业务系统约定好数据接口，并让业务系统按照数据接口格式生成数据文件和完结标示文件给到ODS。

  这种方式一方面可以降低ODS处理多种类型数据库系统能力需求，另一方面也减少了对业务系统的性能影响。但是不足之处在于数据的抽取过程和加载过程隔离开来由业务系统和ODS分别负责，接口新增和变更比较麻烦，需要较大的沟通维护成本，也将一部分工作上前推到了业务系统这边，同时数据落地到文件增加了额外的上传下载工作，性能上是比较差的。

  下图是文件同步的系统架构图：

![ods_2_1-0](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/b5592255cf438eb98cabb7d9c251b819/ods_2_1-0.png)

  下面是文件同步的接口定义的一个实际例子：

  1、 物理结构

  ODS系统和业务系统数据之间通常需要有一个中转站，一般是一个FTP服务器，并且需要定义多个目录来存放不同的接口文件。所以接口文件中需要给出FTP的地址、用户名密码以及接口文件存放的目录

  2、 明确双方责任

  1） 业务系统的责任

  负责抽取数据，生成接口文件，并上传到FTP服务器，如果数据存在问题需要处理后并重新生成接口文件并重新上传

  同时需要保障接口文件在约定的时间内及时上传

  2） ODS系统的责任

  负责维护FTP服务器，并采集接口文件做入库，如果存在问题需要通知业务系统做修正重传

  3、 接口文件相关规范

  1） 接口文件的交互机制

  首先由业务系统抽取相关数据生成接口数据文件，并上传到FTP服务器约定的目录中，在上传过程中重命名接口数据文件为：TMP_接口数据文件名。

  完成上传后，接口名改为正常的名称，同时上传接口标示文件，用以标示接口数据文件已完成上传。

  ODS系统循环检测接口标示文件，核对标示文件中的文件名是否在FTP服务器存在，如果存在则下载接口数据文件并入库，完成入库后校验标示文件中的记录数是否和入库记录数一致。这中间如果失败，则通知业务系统重传接口文件。

  2） 命名规范

  例如：接口文件名称_文件上传日期_数据日期_重传次数_文件拆分序列号.后缀。

  3） 接口文件编码格式

  接口文件需要采用统一的编码，这样ODS系统入库才不需要做额外的解码工作。

  4） 接口文件分隔符

  为了避免字段错列，需要用一种数据中不太可能包含的字符。通常会定义个不可输入的字符，例如0x05。

  5） 压缩算法

  主要是为了加快数据入库，另一方面目前流行的分布式算法是支持压缩文件的，解压的工作可以在分布式系统内自动实现。但是如果ODS系统不是Hadoop等分布式系统，而是采用传统的MPP数据库或者关系型数据库，则这块工作可以忽略。

  6） 加密算法

  敏感数据需要加强安全控制，需要对文件做加密处理。

  4、 接口文件定义

  这里以一个会员表举例

  1） 接口文件命名

  Member_201512160233_20151215_00_01.dat

  2） 表结构

| 字段 | 字段名称 | 字段类型 |
| ---- | -------- | -------- |
| ID   | 会员ID   | Int      |
| Name | 会员名称 | String   |

  3） 接口文件上传时间

  每天凌晨抽取，3点前上传到FTP接口机

  4） 抽取方式（全量or增量）

  全量抽取



## 2）数据库表抽取

### 数据库直连同步

  数据库直连的方式一般是全量抽取，在特定的时刻抽取业务系统数据到ODS系统。下图是数据库直连同步的系统架构图：

![ods_2_1](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/5c1874e80c4f08d8bf5aa51ed0cb82f9/ods_2_1.png)

  数据库直连抽取的优势是配置简单快捷、数据准确性高，但是这种抽取方式存在一定的局限性：

- 对源系统性能存在一定的影响，在业务系统存在主备库的时候，优先抽取备库；

- 抽取增量数据需要依靠修改业务系统，新增时间戳字段，并且按时间戳增量抽取的数据准确性不能得到保障，业务系统做数据补丁不更新时间戳字段将会导致漏数；

- 只能在某个时刻抽取数据，不能满足准实时数据需求；

- 大批量的数据抽取性能较差；
  综合来看，数据库直连抽取比较适用于小批量表的数据抽取

  

### 数据库日志抽取

  数据库日志抽取是指通过分析数据库日志，将业务系统的DDL和DML语句在一个镜像系统还原，并通过数据流的方式对外提供实时数据服务。下面是数据库日志抽取的架构图：

![ods_2_1-2](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/b38a9ceb02560a74e123b6354b8f47ee/ods_2_1-2.png)

  由于是数据库日志抽取是获取所有的变更记录，落地到ODS表的时候我们需要根据主键去重按照日志时间倒排序获取最后状态的变化情况。而且不同的场景我们可以采用一些不同落地手法：

![ods_2_1-3](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/35b3ae2ed8c9522b7fb69a3a50f352e8/ods_2_1-3.png)

  从上面的图片我们可以看出，有三种处理方式

- 不过滤
  不管是否是删除记录，获取同一主键最后变更的那条记录

- 只过滤最后一条delete
  如果同一主键最后变更的那条记录是删除记录，就获取倒数第二条记录

- 过滤delte和之前的数据
  如果同一主键变更的中有删除记录，根据操作时间该删除记录之前的记录都过滤

  

  这几种处理方式主要针对删除记录，因此要看前端是如何删除无效数据的：

- 手工批量删除
  这种通常是DBA将部分历史数据直接删除或者备份到备份库。
- 逻辑删除，不物理删除
- 正常业务删除数据

  如果明确业务数据不存在业务上的删除数据，但是存在手工删除或备份数据的，例如商品、会员等，可以采用只过滤最后一条delte的这种方式（记录是否有效可以通过状态字端来判断）。

  一般情况可以采用不过滤的方式来处理，下游通过是否删除记录的标来判断是否删除记录。



  存在的问题：

- 数据延迟
  例如业务系统做批量补丁可能会使数据更新量超出系统处理峰值，导致数据延迟
- 投入较大
  采用数据库日志抽取的投入较大，需要在业务系统和ODS之间再部署一个系统实时抽取数据。
- 数据飘移和遗漏
  数据飘移，一般是对于ODS增量表而言的，通常是指ODS表的同一个业务日期数据中包含前一天或后一天凌晨附近的数据或者丢失当天的变更数据。这个问题我们将在数据质量处理的数据飘移处理这一节中详细论述

### 3）原始日志抽取

  在电商数据仓库中至关重要的用户访问日志数据是不会直接落地到数据库中的，所以需要直接在后端部署日志采集。

  下面是淘宝做的日志采集方案：

![ods_2_1-4](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/8846e0254a7df585b991e503148ba852/ods_2_1-4.png)

  1、浏览器发送请求到web服务器(web server)

  2、web服务器响应请求, 经过一系列处理后, 返回浏览器页面资源(html page). 部署在web服务器上的beacon模块(beacon module)捕获响应, 在页面html代码的<body>标签后插入一段js代码, 即<script>(与beacon的<img>相对应)标签对

  3、被修改的页面发送到浏览器, 浏览器开始渲染页面. 执行到上述js时, js会动态在页面中创建另一个<script>标签, 其src属性被设置为一段存储在CDN server上的js



  4、浏览器渲染新建的<script>, 向CDN server异步请求js脚本文件. (异步请求不会阻塞页面加载)

  5、CDN server响应浏览器js脚本文件

  6、js脚本在当前域下运行, 收集相关信息(主要是cookie信息), 然后将这些信息拼装为query串, 在页面中动态生成一个<img>标签, 设置其src为日志服务器(log server)上的一个图片url, 在url后面附上准备好的query串. 浏览器渲染该<img>, 向日志服务器(log server)请求图片. 该请求会自动携带所属域(log server: www.b.com)的cookie信息(第一次访问无cookie信息)

  7、日志服务器(log server)收到请求后, 从query串和请求头部(http request header)中解析信息(第一次访问会在log server分配生成cookie信息), 写入本地日志文件(log file)

  8、第一次访问(或者原来的cookie被清除), 会由log server生成一个新的ID(cna). 在设置客户端 mmstat 域 cna cookie的同时, 在response header中会有一个location指令(response的状态码为302, 重定向资源), 要求浏览器重定向到 pcookie.taobao.com/app.gif?cna=xxx.

  9、浏览器重定向到pcookie.taobao.com/app.gif?cna=xxx

  10、taobao.com服务器收到该请求, 响应一个1x1像素的图片, 同时在 taobao.com域下设置一个cna cookie, 和mmstat域的cna一致。



# 数据质量处理

首先整体介绍数据质量相关的内容，然后重点针对ODS数据质量在数据监控和数据清洗方面做介绍。

# 处理方法

数据数据质量的基本要求为数据的五性：准确性、及时性、一致性、完整性、逻辑性：

- 准确性
  包含了真实性和准确性，真实性是数据符合事实、标准或真实情况，没有误差或偏差；准确性是数据值与设定为准确的值之间的一致程度，或与可接受程度之间的差异。如：某指标的准确程度
- 及时性
  指数据刷新、修改和提取等操作的及时性和快速性，按规定时限要求完成。
- 一致性
  同一信息主体在不同的数据集中信息属性相同的，如：各级报表统计口径一致，出现差异的原因可解释，可追溯
- 完整性
  从数据定义、数据录入、规则约束三方面保障数据的完整。如：实体不缺失、属性不缺失、记录不缺失、字段值不缺失、主键不缺失
- 逻辑性
  各项数据之间符合业务逻辑关系，如：在业务口径一致的基础上，报表的各项数据之间符合相应的逻辑关系，尤其表现在数据之间。

## 1）处理方法

### 稽核指标设计

通常我们需要根据不同类型、不同对象的数据质量问题设计不同的稽核指标：

| 数据质量要素  | 稽核指标对象 | 指标样例                                       |
| ------------- | ------------ | ---------------------------------------------- |
| 及时性        | 表级         | 实体表是否在约定的时间范围内产出               |
| 波动性/准确性 | 表级         | 实体表的记录数波动小于阈值                     |
| 完整性        | 字段级       | X表主键字段非空、唯一                          |
| 波动性/准确性 | 字段级       | X表XX字段（未知和其他的记录数）/总记录数据<10% |
| 逻辑性        | 字段级       | X表XX字段 in （0,1,2,3）or 税前收入<税后收入   |
| 波动性/准确性 | 指标级       | 当日有效会员数波动小于阈值                     |
| 逻辑性        | 指标级       | 当日有效会员数>当日有效天猫会员数              |
| 波动性/准确性 | 任务级       | 是否超出最近一周的平均执行时长                 |
| 及时性        | 任务级       | 是否超出约定的时长                             |

### 稽核指标算法

1. 最大值： 求日期、数值类型字段最大值，通常会列出最大值排序后前5个记录，公式：f(x)=MAX(x) 可利用SQL中MAX(Fieldl)函数实现。
2. 最小值： 求日期、数值类型字段最小值，通常会列出最小值排序后前5个记录。公式：f(x)=Min(x) 可利用SQL中MIN (Fieldl)函数实现。
3. 平均值： 求日期、数值类型字段的平均值。可利用SQL中AVG (Fieldl) 函数实现。
4. 非法值比率： 求字段非法比率，通常还会通过字段的非法率计算出表的非法率。累计为非法值定义f1,合法值为f2,计算 f1/(f1+f2)
5. 唯一率：求字段的唯一率。 统计表中非重复记录数,定义为f2,所有记录数定义为f1,通过公式f2/f1得到唯一率。
6. 外关联法 通过主从两表的外关联，查找从表中缺少的记录。
7. 抽样检查法 对于大量的数据，无法逐一跟踪质量情况，可以采用1%抽样，或者指定抽样比率进行抽查。
8. 移动平均法 移动平均法是基本的、也是最普遍使用的时间序列方法，用前T期的数据计算第T+1期数据的预测值，以及该预测值的上下限范围。
9. 指标平衡法 指标平衡法是用报表中的指标之间的关系进行平衡检查，查看这些指标是否满足最基本的平衡关系。
10. 比例测试法 利用数据在关键性指标上的分布比例是否合理。例如，地区收入和用户比例的关系等。

# 数据监控

数据监控的流程一般分为两种：

- 串行式

  串行式的监控方式一般适用于相对比较重要的稽核指标，一旦稽核不通过就需要打断ETL任务的继续执行，详细流程可以查看下图： ![ods_2_2-1](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/b3a825d57e7dd72aba7ad1ad298e9c21/ods_2_2-1.png)

  

- 并行式

  串行式的监控方式一般适用于相对不是特别重要的稽核指标，稽核流程并不影响ETL任务的执行，并且稽核的过程和ETL是并行执行的，详细流程可以查看下图： ![ods_2_2-2](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/d615f27b5182cf6ca5aa1239cc1218bd/ods_2_2-2.png)

  通过前文我们可以看出串行的方式严格保障了数据质量，但是会对ETL任务和数据的产出性能带来比较大的影响，而并行这种方式的优势是不会影响任务和数据的产出，但是如果发现了数据质量问题，需要在事后进行处理。所以通常我们在日常生产中这两种方式联合使用的，一般来说数据仓库不同层次的数据稽核的标准也是有所差异的，ODS相对来说较为注重的是数据的及时性、完整性以及和源系统的一致性，逻辑性和准确性的稽核指标，我们可以通过推动业务系统加入更多的校验来保障。所以一般可以将一些完整性的指标，例如主键非空等指标设置为串行的方式，而一些阈值范围类的稽核指标设置为并行处理。



# 数据清洗

我们在长期的生产实际过程中，发现部分已知的数据问题的处理可以通过自动化的方式来处理，这种方式通常在数据入库之前，做额外的加工处理后再做入库操作。下图是数据清洗的流程图：

![ods_2_2-3](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/4e6a18e4710d072dcda38fa64e071335/ods_2_2-3.png)

数据清洗主要对象是那些不符合要求的数据，具体为不合规的数据、错误的数据、重复的数据三大类。

- 不合规的数据

  例如，在淘宝很多前端系统都是通过API的方式对外提供接口，部分接口方如果不按照开发规范，很多字段都会出现非法字符，这种数据在前端很多时候都是不关心或者不希望额外投入资源去处理。因此就需要在数据清洗的时候做一些处理，例如对某些中文字段进行统一编码，对字段中包含特殊字符（换行符）进行清理，对时间类字段统一到秒的格式。

- 错误的数据

  一类错误产生的原因是业务系统不够健全，在接收输入后没有进行判断直接写入后台数据库造成的，比如数值数据输成全角数字字符、字符串数据后面有一个回车操作、日期格式不正确、日期越界等。

- 重复的数据

  例如，一些前端系统迁移过后的新老表融合可能会存在大量的重复历史数据，这也可以在数据清洗这一步骤中完成消除重复数据的操作。 需要注意的是，在数据清洗后还需要对ODS的数据做稽核，还需要对脏数据做稽核校验，脏数据的校验主要集中在数据量上，如果数据量波动特别大则需要人工介入处理。



# ODS表的设计方法

在引言部分我们已经论述过ODS的概念特征，既要和业务系统保持一致，又不完全等同于业务系统。所以在设计ODS物理表时，在表命名、数据存储等方面都需要遵循一定的准则。

## 命名规则

不管是表命名还是字段命名尽量保持和业务系统保持一致，但是需要通过额外的标识来区分增量和全量表。例如，我们通过”_delta”来标识该表为增量表。在命名这块需要特别注意冲突处理，例如不同业务系统的表可能是同一个名称，为了区分这两个不同表，我们可以将这两个同名表的来源数据库名称作为后缀或前缀。例如，表中某些字段的名称刚好和关键字重名了，我们也可以通过规范定义后缀添加一个“_col1”来解决。

## 存储方式

为了满足历史数据分析需求，我们需要在ODS表中加一个时间维度，这个维度我们通常在ODS表中作为分区字段。

- 增量存储

按天为单位的增量存储，即是说用业务日期作为分区，每个分区存放日增量的业务数据。

例一：1月1号，用户A访问了淘宝店铺B，淘宝日志会产生一条记录t1；1月2号，用户A又访问了淘宝店铺C，淘宝日志会产生一条记录t2；采用增量存储方式，那么t1将存储在1月1号这个分区中；t2将存储在1月2号这个分区中。

例二，1月1号，用户A在淘宝网购买了B商品，交易日志将生成一条记录t1；1月2号，用户A又将B商品退货了，交易日志将更新t1记录；采用增量存储方式，初始购买的t1记录将存储在1月1号这个分区中；更新后的t1将存储在1月2号这个分区中。

- 全量存储

按天为单位的全量存储，即是说用业务日期作为分区，每个分区存放截止到业务日期为止的全量业务数据。

例三，1月1号，卖家A在淘宝网发布了B、C两个商品，前端商品表将生成两条记录t1、t2；1月2号，卖家A将B商品下架了，同时又发布了商品D，前端商品表将更新记录t1，又新生成记录t3；采用全量存储方式， 在1月1号这个分区中存储t1和t2两条记录；在1月2号这个分区中存储更新后的t1以及t2、t3记录。数据存储如下：

| 商品 | dt       | 卖家 | 状态 | 其他字段 |
| ---- | -------- | ---- | ---- | -------- |
| B    | 20160101 | A    | 上架 | ...      |
| C    | 20160101 | A    | 上架 | ...      |
| B    | 20160102 | A    | 下架 | ...      |
| C    | 20160102 | A    | 上架 | ...      |
| D    | 20160102 | A    | 上架 | ...      |

这种存储方式类似维度模型中的周期性快照的处理手法，消耗存储成本来换取易用性：容易理解、各种场景的应用都通用，但是还会有下游扫描额外的数据导致计算成本消耗的问题，所以这类存储方式比较试用于小型的维度数据。

- 历史拉链存储

历史拉链存储是指利用维度模型中缓慢变化维TYPE2的处理方式。这种处理方式是通过新增两个时间戳字段（start_dt和end_dt），将所有以天为粒度的变更数据都记录下来，通常分区字段也是这两个时间戳字段。

如果我们采用历史拉链存储，数据存储如下，对于不变的数据，不再重复存储。

| 商品 | dt       | 卖家 | 状态 | 其他字段 |
| ---- | -------- | ---- | ---- | -------- |
| B    | 20160101 | A    | 上架 | ...      |
| C    | 20160101 | A    | 上架 | ...      |
| B    | 20160102 | A    | 下架 | ...      |
| D    | 20160102 | A    | 上架 | ...      |

这样下游应用可以通过限制 时间戳字段来获取历史数据，例如， 用户访问1月1号的数据，只需要限制： `stat_dt<=20160101 and end_dt>20160101`。

但是这种存储方式对于下游使用方的存在一定的理解障碍，特别是ODS的数据面向的下游用户包含数据分析师、前端开发等，这些人群不怎么理解维度模型的概念，因此会存在较高的解释成本。另一方面，这种存储方式用 start_dt和end_dt作分区，随着时间的推移，分区数量会极度膨胀，而现行的数据库系统都有分区数量限制。



- 极限存储

为了解决上述的两个问题，我们提出极限存储的方式处理。具体细节请参考维度部分的维度变化-极限存储章节。



- 三种存储方式比较

| 存储方式              | 存储成本 | 计算成本 | 下游易用性                                                   | 局限性                                                       |
| --------------------- | -------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 增量存储              | 低       | 低       | 扫描量小 使用效率高 容易理解 适用特定场景                    | 源表存在更新时 不能满足全局性数据获取的需求                  |
| 全量存储              | 高       | 低       | 扫描量大 使用效率低 容易理解 适用各种场景                    | 存储成本太高 下游使用效率低                                  |
| 历史拉链存储 极限存储 | 低       | 较高     | 扫描量较大使用效率适中 专业性强解释成本高（极限存储没有这个问题） 适用特定场景 | 本身产出的计算成本较高 一旦存在数据质量问题后续维护成本高 只适用于缓慢变化的表 |

根据前文描述的存储方式特点，我们可以得出不同场景选用不同存储方式：

1）通常来说类似交易、日志等事务性较强的ODS表比较适合用于增量存储方式，这类表一方面数据量比较大，采用全量存储的方式存储成本压力太大，另一方面这类表的下游应用对于历史全量数据访问的需求不大（这类需求都通过数据仓库后续汇总后得到），或者例如日志类ODS表不会有数据更新的业务过程，所以所有增量分区unoin在一起就是一份全量数据。

2）对于大数据量的缓慢变化的维度数据，例如用户、商品等，我们建议采用极限存储的方式来处理。

3）对于快速变化的维度数据，例如用户星级、用户积分等，时间粒度如果粗到天往往不能满足下游的应用需求，比如下游需要统计用户星级发生变化的次数，采用全量存储的方式也不能满足这类应用，所以我们可以将这类快速变化的维度数据每次变更记录都记录下来变为一张用户星级变化流水表作增量存储

4）对于小数据量的缓慢变化的维度数据，例如商品类目，我们可以直接用全量存储

## 生命周期

一般来说数据本身存在一个生命周期过程：

![ods_2_3-1](http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/yongwei.wangyw/model/f88124fc86d2be379a852dd2c9e37ffa/ods_2_3-1.png)

这个过程对于数据研发人员而言通常只有一个模糊的概念，在具体实施过程也通常手工批量执行，而实际上不同的数据的生命周期过程是不同的，这种手工处理的效率和管理精细度都比较低。考虑到数据从生产到消亡和时间具有强关联性，我们以ODS表的分区为对象，给每个对象设置一个生命周期时间，一旦超过这个生命周期则该对象自动消亡。

例如用户全量表，每天都会生成一个全量分区，如果所有下游用户只需要访问当天的全量分区，那么我们可以将这个用户全量表的生命周期设置为1，这样1天前生成的全量历史分区自动会被删除。



# 应用场景分析

## 分析角度

一般来说对于ODS表的设计方案选择，主要从几个角度考虑：

1. 应用需求

   从数据仓库的设计原理出发，ODS是需要满足在时间粒度上以天为粒度，数据最多延迟1天，并在一定的时间范围内提供应用查询历史某一天的业务系统数据。但是随着业务的发展，应用需求有所发展：
   时间粒度上有特殊需求的，粒度需要统计小时或分钟的数据；
   需要获取维度类数据有史以来所有变更数据；
   需要获取业务系统删除的数据；
   需要获取某一特定时刻业务系统的全量数据

   

2. 产出性能

   选用同样全量存储的方式，采用不同的抽取方式的性能是不一样的。一般来说，直接用数据库直连的方式抽取大批量数据的性能是比较低的，选用抽取按天为增量的数据然后merge到全量存储的方式可以缓解产出性能的降低。但是这种处理方法有比较多的局限性，一方面用时间戳获取增量可能漏数据，手工补丁不更新时间戳数据就可能遗漏，另一方面可能即使是增量抽取的数据量级别仍然达到千万级别以上，产出性能并不会有很大的提升。

   采用数据库日志抽取基本不存在上述的问题，但是采用数据库日志抽取的投入较大，需要在业务系统和ODS之间再部署一个系统实时抽取数据。如果业务本身没有达到一定的量级或者不需要支持实时数据需求，还是需要综合评估下的。

   

3. 存储成本

   毫无疑问，历史数据和存储成本是一对矛盾体。对于满足一定的时间范围内提供应用查询历史某一天的业务系统数据这个需求点，需要注意的是数据仓库对接的不是单一的业务系统，不同业务对于数据查询的时间范围是不一样的。所以不同ODS表的历史数据存储长短也是有差异的。另一方面，对于部分全量数据我们可以采用极限存储的方式来降低一定的存储压力。

   

4. 数据质量

   ODS数据有一个基本的数据质量要求：数据和前端系统保持一致。 通常来说，普遍要求是在满足应用需求的前提下尽量提高产出性能降低存储成本。

## 具体方案的选择

| 场景                                     | 方案（抽取、存储、生命周期）                                 |
| ---------------------------------------- | ------------------------------------------------------------ |
| 小数据量缓慢变化维表                     | 数据库直连全量抽取 按天全量存储 生命周期设置长周期           |
| 大数据量缓慢变化维表                     | 数据库日志解析增量抽取 按天全量存储+极限存储 生命周期设置为永久 |
| 巨型数据量缓慢变化维表                   | 数据库日志解析增量抽取 按天全量存储（拆分数据，详见下一章“巨型表的处理”一节）+极限存储 生命周期设置为永久 |
| 快速变化维表                             | 数据库日志解析增量抽取 按天增量存储（转变为变化流水表） OR 按天全量存储 生命周期设置为永久 |
| 日志表                                   | 原始日志增量抽取 按天增量存储 生命周期设置为永久             |
| 大数据量事务表                           | 数据库日志解析增量抽取 按天增量存储+按天全量存储 增量存储：生命周期设置为永久，全量存储：保留月头、生命周期设为短期（结合下游使用情况设置，如7天、30天等） |
| 巨型数据量事务表1 （没有全量访问需求的） | 数据库日志解析增量抽取 按天增量存储 生命周期设置为永久       |
| 巨型数据量事务表2 （有全量访问需求的）   | 数据库日志解析增量抽取 按天增量存储+最近N天全量存储（如200天）+极限存储（拆分数据，详见下一章“巨型表的处理”一节） 生命周期设置为永久 |

备注：
一般来说 巨型数据量：亿级；大数据量：百万、千万级；小数据量：低于百万级







